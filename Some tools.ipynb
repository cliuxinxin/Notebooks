{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看环境安装情况\n",
    "!pip freeze | grep tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看文件行数\n",
    "!wc -l data/poetry/*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看文件内容\n",
    "!head -5 data/poetry/*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多文件操作\n",
    "with open('data/poetry/raw.txt', 'r') as rawfp,\\\n",
    "  open('data/poetry/input.txt', 'w') as infp,\\\n",
    "  open('data/poetry/output.txt', 'w') as outfp:\n",
    "    \n",
    "    prev_line = ''\n",
    "    for curr_line in rawfp:\n",
    "        curr_line = curr_line.strip()\n",
    "        # poems break at empty lines, so this ensures we train only\n",
    "        # on lines of the same poem\n",
    "        if len(prev_line) > 0 and len(curr_line) > 0:       \n",
    "            infp.write(prev_line + '\\n')\n",
    "            outfp.write(curr_line + '\\n')\n",
    "        prev_line = curr_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#github忽略文件\n",
    "touch .gitignore\n",
    "vi .gitignore\n",
    "# 忽略文件夹\n",
    "/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并checkpoints\n",
    "python avg_checkpoints.py --checkpoints=[tacotron_model.ckpt-345000,tacotron_model.ckpt-350000] --output_path=\"/Users/liuxinxin/Downloads/new.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reduce_mean 说明\n",
    "a = tf.random_uniform([2,3],minval=5,\n",
    "    maxval=5,)\n",
    "# [[5. 5. 5.]\n",
    "#  [5. 5. 5.]]\n",
    "b = tf.reduce_mean(a,-1)\n",
    "# [5. 5.]\n",
    "b = tf.reduce_mean(a)\n",
    "# 5.0\n",
    "b = tf.reduce_mean(a,-1,keepdims=True)\n",
    "# [[5.]\n",
    "#  [5.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用request访问api\n",
    "import requests\n",
    "\n",
    "sentences = \"测试语句\"\n",
    "url = 'http://127.0.0.1:19877/?sentences=' + sentences\n",
    "crawl_content = requests.get(url)\n",
    "crawl_content.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 异步访问\n",
    "async def call_coroutine(session, url,i,files):\n",
    "    with async_timeout.timeout(60):\n",
    "        async with session.get(url) as response:\n",
    "            content = await response.text()\n",
    "            content = json.loads(content)\n",
    "            files[i] = content['wav_file']\n",
    "            print(content['wav_file'])\n",
    "            print(i)\n",
    "            return await response.release()\n",
    " \n",
    " \n",
    "async def main(loop,sentences,files):\n",
    "    async with aiohttp.ClientSession(loop=loop) as session:\n",
    "        tasks = [call_coroutine(session, 'http://127.0.0.1:8099/?sentences=' + sentence,i,files) for i,sentence in enumerate(sentences)]\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "def synic(sentences):\n",
    "    start = time()\n",
    "    files = {}\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    loop.run_until_complete(main(loop,sentences,files))\n",
    "    files  = sorted(files.items(),key = lambda item:item[0])\n",
    "    files = [file[1]+'.wav'  for file in files]\n",
    "    if len(files) > 1:\n",
    "        break_wav = [\"480ms.wav\"] * (len(files) - 1)\n",
    "        j = 1\n",
    "        for i, ele in enumerate(break_wav):\n",
    "            files.insert(i + j, ele)\n",
    "            j += 1\n",
    "        files = ['wav_out/' + filename for filename in files]\n",
    "        cbn = sox.Combiner()\n",
    "        nowTime = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "        output_file = 'wav-' + nowTime + '.wav'\n",
    "        cbn.build(files, 'wav_out/' + output_file, 'concatenate')\n",
    "    else:\n",
    "        output_file = files[0]\n",
    "    stop = time()\n",
    "    print(stop - start)\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置互信\n",
    "# 生成秘钥\n",
    "ssh-keygen -t rsa\n",
    "# 把id_rsa.pub内容写入authorized_keys中\n",
    "# 修改权限\n",
    "chmod 700 .ssh #.ssh权限\n",
    "chmod 600 authorized_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ubuntu 压缩文件\n",
    " tar -zcvf workspace.tar.gz worksapce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send command:\n",
      "scp -P 22 /Users/liuxinxin/Downloads/checkpoint.zip zpf@124.126.217.105:/home/zpf/exp/ta-2/logs-Tacotron/taco_pretrained/\n",
      "rece_command:\n",
      "scp -P 22 zpf@124.126.217.105:/home/zpf/exp/ta-2/logs-Tacotron/taco_pretrained/checkpoint.zip /Users/liuxinxin/Downloads/\n"
     ]
    }
   ],
   "source": [
    "# 生成传输数据\n",
    "\n",
    "dict_server_dir = {\n",
    "    \"align\":\"/home/zpf/exp/ta-2/logs-Tacotron/eval-dir/plots\",\n",
    "    \"model\" : \"/home/zpf/exp/ta-2/logs-Tacotron/taco_pretrained\",\n",
    "    \"usr\" : \"/usr\",\n",
    "    \"wav\" : \"/home/zpf/exp/ta-2/logs-Tacotron/eval-dir/wavs\"\n",
    "}\n",
    "\n",
    "dict_file = {\n",
    "    \"align\" : \"step-60000-eval-align.png\",\n",
    "    \"wav\" : \"step-35000-eval-wave-from-linear.wav\",\n",
    "    \"model\" : \"checkpoint.zip\"\n",
    "}\n",
    "\n",
    "dict_server = {\n",
    "    \"zpf\" : {\n",
    "        \"admin\" : \"zpf\",\n",
    "        \"address\" : \"124.126.217.105\"\n",
    "    },\n",
    "    \"206\" : {\n",
    "        \"admin\" : \"root\",\n",
    "        \"address\" : \"112.126.80.206\"\n",
    "    }\n",
    "}\n",
    "\n",
    "server = dict_server[\"zpf\"]\n",
    "\n",
    "server_admin = server[\"admin\"]\n",
    "server_address = server[\"address\"]\n",
    "server_dir = dict_server_dir[\"model\"]\n",
    "home_dir = \"/Users/liuxinxin/Downloads\"\n",
    "file_name = dict_file[\"model\"]\n",
    "\n",
    "\n",
    "send_command = \"scp -P 22 \"+ home_dir + \"/\" + file_name + \" \" + server_admin + \"@\" + server_address + \":\" + server_dir + \"/\"\n",
    "rece_command = \"scp -P 22 \"+ server_admin + \"@\" + server_address + \":\" + server_dir+ \"/\" + file_name + \" \" + home_dir + \"/\"\n",
    "\n",
    "print(\"send command:\")\n",
    "print(send_command)\n",
    "print(\"rece_command:\")\n",
    "print(rece_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint.zip                                100%  303MB   2.2MB/s   02:17    \n"
     ]
    }
   ],
   "source": [
    "!$rece_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.zip                                         100%  622MB   2.0MB/s   05:17    \n"
     ]
    }
   ],
   "source": [
    "!$send_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看端口占用情况\n",
    "lsof -i tcp:8099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json不能传输ndarray的问题，如果解决\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# ndarray 无法序列化\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "print(json.dumps({'aa': [2, (2, 3, 4), a], 'bb': [2]}, cls=NumpyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mac sh 文件可以执行\n",
    "chmod u+x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 大文件查询\n",
    "du --max-depth=1 -h ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装redis\n",
    "下载https://redis.io/download\n",
    "$ cd redis-3.2.8\n",
    "$ make\n",
    "$ sudo make install \n",
    "# 运行\n",
    "/usr/local/bin\n",
    "redis-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junxi\n",
      "junxi\n",
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用redis 和 删除key\n",
    "import redis   # 导入redis模块，通过python操作redis 也可以直接在redis主机的服务端操作缓存数据库\n",
    "\n",
    "r = redis.Redis(host='localhost', port=6379, decode_responses=True)   # host是redis主机，需要redis服务端和客户端都启动 redis默认端口是6379\n",
    "# r.set('name', 'junxi')  # key是\"foo\" value是\"bar\" 将键值对存入redis缓存\n",
    "# print(r['name'])\n",
    "# print(r.get('name'))  # 取出键name对应的值\n",
    "r.hset(name, key, value) \n",
    "print(type(r.get('name')))\n",
    "\n",
    "keys = r.keys()\n",
    "r.delete(*keys)\n",
    "r.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "['五千', '四百', '三十三万', '五千', '八百', '二十一']\n"
     ]
    }
   ],
   "source": [
    "sentences = \"五千&四百&三十三万&五千&八百&二十一\"\n",
    "\n",
    "hasMS=False\n",
    "sentences=sentences.split(\"&\")\n",
    "if(len(sentences)>0):\n",
    "    hasMS=False\n",
    "else:\n",
    "    sentences=sentences.split(\"。\")\n",
    "    hasMS=True\n",
    "\n",
    "    \n",
    "print(hasMS)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "符号： ['，', '。', '，', '。']\n",
      "文字： ['你好', '我是深度学习工程师', '他是java工程师', '而且还是单身']\n"
     ]
    }
   ],
   "source": [
    "# 分割句号和逗号\n",
    "strs = '你好，我是深度学习工程师。他是java工程师，而且还是单身。'\n",
    "arrays = list(filter(None,strs.split('。')))\n",
    "fuhao = []\n",
    "chars = []\n",
    "for line in arrays:\n",
    "    lines = list(filter(None,line.split('，')))\n",
    "    if len(lines) > 1:\n",
    "        for i in range(len(lines)-1):\n",
    "            chars.append('，')\n",
    "        chars.append('。')\n",
    "    else:\n",
    "        chars.append('。')\n",
    "    fuhao.extend(lines)\n",
    "print(\"符号：\",chars)\n",
    "print(\"文字：\",fuhao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "符号： ['，', '。', '，', '。']\n",
      "文字： ['你好', '我是深度学习工程师', '他是java工程师', '而且还是单身']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuxinxin/anaconda3/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "# 分割句号和逗号\n",
    "import re\n",
    "\n",
    "sentences = \"你好，我是深度学习工程师。他是java工程师，而且还是单身。\"\n",
    "fields = re.split(r'(。|，|)', sentences)\n",
    "values =  list(filter(None,fields[::2]))\n",
    "delimiters = fields[1::2]\n",
    "\n",
    "print(\"符号：\",delimiters)\n",
    "print(\"文字：\",values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好1我是深度学习工程师0他是java工程师1而且还是单身0\n"
     ]
    }
   ],
   "source": [
    "# 合并结果\n",
    "word = []\n",
    "for value,delimiter in zip(values,delimiters):\n",
    "    word.append(value)\n",
    "    break_value = \"0\"\n",
    "    if delimiter == '，':\n",
    "        break_value = '1'\n",
    "    word.append(break_value)\n",
    "word = ''.join(word)\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67f12172333b84b312b36a247d8d0ce1\n"
     ]
    }
   ],
   "source": [
    "# MD5生成\n",
    "data = \"问题解决了，但是心头的疑问却更多了。为什么不能直接hashlib.md5(data)，非要强制进行编码转换，设计者的初衷何在？中文字符在Python中是以什么形式存在？说明中文字符在Python中是以unicode存在的。至此，所有的疑问都得以解除了。在hash前要求进行编码转换，是因为同一个字符串在不同的编码体系下有不同的值，为确保不发生歧义必须要进行一次显性转换。\"\n",
    "m = hashlib.md5(data.encode())\n",
    "print(m.hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手工实现矩阵算法\n",
    "import numpy as np\n",
    "def elementwise_multiplication(vec_a, vec_b):\n",
    "    vec_result = np.zeros(vec_a.shape)\n",
    "    for i,item in enumerate(zip(vec_a,vec_b)):\n",
    "        c = item[0] * item[1]\n",
    "        vec_result[i] = c\n",
    "    return vec_result\n",
    "\n",
    "def elementwise_addition(vec_a, vec_b):\n",
    "    vec_result = np.zeros(vec_a.shape)\n",
    "    for i,item in enumerate(zip(vec_a,vec_b)):\n",
    "        c = item[0] + item[1]\n",
    "        vec_result[i] = c\n",
    "    return vec_result\n",
    "\n",
    "def vector_sum(vec_a):\n",
    "    result = 0\n",
    "    for a in vec_a:\n",
    "        result += a\n",
    "    return result\n",
    "\n",
    "def vector_average(vec_a):\n",
    "    a_sum = vector_sum(a)\n",
    "    average = a_sum / len(a)\n",
    "    return average\n",
    "\n",
    "def dot_product(vec_a, vec_b):\n",
    "    elementwise = elementwise_multiplication(vec_a, vec_b)\n",
    "    result = vector_sum(elementwise)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看某个进程的资源占用\n",
    "top -c -p $(pgrep -d',' -f guni)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
